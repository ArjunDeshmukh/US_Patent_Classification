{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries\n"
      ],
      "metadata": {
        "id": "83YXgK8eC0_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False"
      ],
      "metadata": {
        "id": "6x774kWbGeJI",
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:01.173542Z",
          "iopub.execute_input": "2022-10-17T22:51:01.174006Z",
          "iopub.status.idle": "2022-10-17T22:51:01.199311Z",
          "shell.execute_reply.started": "2022-10-17T22:51:01.173893Z",
          "shell.execute_reply": "2022-10-17T22:51:01.198471Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "69ZldWGCDQ7n",
        "outputId": "a34a2ae3-6d72-4879-a28e-b9e9b9bb05b8",
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:01.200901Z",
          "iopub.execute_input": "2022-10-17T22:51:01.201330Z",
          "iopub.status.idle": "2022-10-17T22:51:01.206036Z",
          "shell.execute_reply.started": "2022-10-17T22:51:01.201297Z",
          "shell.execute_reply": "2022-10-17T22:51:01.205014Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "    !pip install transformers"
      ],
      "metadata": {
        "id": "PjYyyi9tGGEL",
        "outputId": "5ed9d293-22e5-4934-9326-1d1395d49674",
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:01.224769Z",
          "iopub.execute_input": "2022-10-17T22:51:01.225048Z",
          "iopub.status.idle": "2022-10-17T22:51:01.229557Z",
          "shell.execute_reply.started": "2022-10-17T22:51:01.225025Z",
          "shell.execute_reply": "2022-10-17T22:51:01.228362Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import sys\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "from transformers import AutoModelForMaskedLM\n",
        "from transformers import AutoModel, AutoConfig, AutoTokenizer, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
        "\n",
        "import torch\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")   \n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device: \", device)\n",
        "\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "from sys import getsizeof\n",
        "import gc"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "e7bR6yPtC0_E",
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:01.268822Z",
          "iopub.execute_input": "2022-10-17T22:51:01.269628Z",
          "iopub.status.idle": "2022-10-17T22:51:08.623314Z",
          "shell.execute_reply.started": "2022-10-17T22:51:01.269595Z",
          "shell.execute_reply": "2022-10-17T22:51:08.622241Z"
        },
        "trusted": true,
        "outputId": "5d09b3c7-f29e-442c-aa10-0362861698b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define configuration constants"
      ],
      "metadata": {
        "id": "FZvI20qjC0_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    CPC_CODES_PATH = \"../input/cpc-code-upto-subclass/CPC_codes_upto_subclass.csv\"\n",
        "    PATENTS_DATA_PATH = \"../input/us-patents-abstracts-cpc/US_Patents_Titles_CPC_Section.csv\"\n",
        "    BERT_FOR_PATENTS_PATH = \"../input/bert-for-patents/bert-for-patents-pytorch\"\n",
        "    DEBERTA_V3_LARGE_PATH = \"../input/deberta-v3-large/deberta-v3-large\"\n",
        "    CPC_CODES_NUM_PATENTS_PATH = \"../input/cpc-code-num-patents/cpc_code_num_patents.csv\"\n",
        "    MAX_TOKEN_LEN = 128\n",
        "    DROPOUT_PROB = 0.2\n",
        "    ATTENTION_INTERMEDIATE_SIZE = 512\n",
        "    GOOGLE_CLOUD_CRED_JSON = '../input/googlecloudcred/us-patent-classification-d344a6ddc702.json'\n",
        "    GOOGLE_CLOUD_PROJ_ID = 'us-patent-classification'\n",
        "    BATCH_SIZE = 64\n",
        "    NUM_EPOCHS = 5\n",
        "    TRAIN_PATENT_START_YEAR = 2001\n",
        "    TRAIN_PATENT_END_YEAR = 2018\n",
        "    TEST_PATENT_START_YEAR = 2019\n",
        "    TEST_PATENT_END_YEAR = 2022\n",
        "    NUM_FOLDS = 6 #Total number of years used for training should be divisible by this number\n",
        "    ENCODER_LR = 2e-5\n",
        "    DECODER_LR = 2e-5\n",
        "    MIN_LR = 1e-6\n",
        "    EPS = 1e-8\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    SCHEDULER = 'linear'\n",
        "    NUM_WARMUP_STEPS = 0\n",
        "    NUM_CYCLES = 0.5\n",
        "    BETAS=(0.9, 0.999)\n",
        "    MAX_GRAD_NORM = 1000\n",
        "    PRINT_FREQ = 50\n",
        "    INFINITY = 1e6\n",
        "    F_TRAIN = 1\n",
        "  \n",
        "  # Parameters which will be added in subsequent code:\n",
        "  # NUM_CLASSES, TRAIN_NUM_PATENTS\n",
        "\n",
        "if IN_COLAB:\n",
        "    CFG.CPC_CODES_PATH = \"/content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Inputs/cpc-code-upto-subclass/CPC_codes_upto_subclass.csv\"\n",
        "    CFG.PATENTS_DATA_PATH = \"/content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Inputs/us-patents-cpc-text/US_Patents_Titles_CPC_Section.csv\"\n",
        "    CFG.BERT_FOR_PATENTS_PATH = \"/content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Inputs/bert-for-patents-pytorch\"\n",
        "    CFG.GOOGLE_CLOUD_CRED_JSON = \"/content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Inputs/googlecloudcred/us-patent-classification-d344a6ddc702.json\""
      ],
      "metadata": {
        "id": "TnAfPfmSC0_G",
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:08.625259Z",
          "iopub.execute_input": "2022-10-17T22:51:08.626201Z",
          "iopub.status.idle": "2022-10-17T22:51:08.636489Z",
          "shell.execute_reply.started": "2022-10-17T22:51:08.626163Z",
          "shell.execute_reply": "2022-10-17T22:51:08.635393Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List of CPC codes"
      ],
      "metadata": {
        "id": "07hZ1QpUC0_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpc_codes_upto_subclass_df = pd.read_csv(CFG.CPC_CODES_PATH)\n",
        "cpc_codes_upto_subclass_df.head()\n",
        "num_codes = len(pd.unique(cpc_codes_upto_subclass_df['code']))\n",
        "sections = pd.unique(cpc_codes_upto_subclass_df['section'])\n",
        "df_len = len(cpc_codes_upto_subclass_df)\n",
        "\n",
        "print(\"Number of rows in dataframe: \", df_len, \"\\n\")\n",
        "print(\"Number of CPC codes upto subclass: \", num_codes)\n",
        "cpc_code_dict = dict(zip(cpc_codes_upto_subclass_df['code'].values, cpc_codes_upto_subclass_df.index))\n",
        "cpc_code_section_dict = dict(zip(sections, range(len(sections))))\n",
        "\n",
        "CFG.NUM_CLASSES = len(sections)"
      ],
      "metadata": {
        "id": "v_Bg2DLLC0_H",
        "outputId": "787611e4-8277-43d3-b91c-aa02588109d5",
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:08.637698Z",
          "iopub.execute_input": "2022-10-17T22:51:08.638199Z",
          "iopub.status.idle": "2022-10-17T22:51:08.685190Z",
          "shell.execute_reply.started": "2022-10-17T22:51:08.638164Z",
          "shell.execute_reply": "2022-10-17T22:51:08.683677Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in dataframe:  674 \n",
            "\n",
            "Number of CPC codes upto subclass:  674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dowloaded Patent Data"
      ],
      "metadata": {
        "id": "FXdNeO0NKtpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patent_data_df = pd.read_csv(CFG.PATENTS_DATA_PATH)\n",
        "patent_data_df.drop(columns = ['Unnamed: 0'], inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:08.687768Z",
          "iopub.execute_input": "2022-10-17T22:51:08.688124Z",
          "iopub.status.idle": "2022-10-17T22:51:19.403049Z",
          "shell.execute_reply.started": "2022-10-17T22:51:08.688088Z",
          "shell.execute_reply": "2022-10-17T22:51:19.402072Z"
        },
        "trusted": true,
        "id": "fH_pzGHjKtpl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_title = np.array(patent_data_df.title.apply(lambda x: len(x)))\n",
        "plt.hist(l_title, bins='auto')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:19.404352Z",
          "iopub.execute_input": "2022-10-17T22:51:19.404719Z",
          "iopub.status.idle": "2022-10-17T22:51:24.156838Z",
          "shell.execute_reply.started": "2022-10-17T22:51:19.404684Z",
          "shell.execute_reply": "2022-10-17T22:51:24.155918Z"
        },
        "trusted": true,
        "id": "PvthU26nKtpm",
        "outputId": "8a35919a-a746-45ea-940d-82eab94fd59b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  2.,   0., 388., ...,   0.,   0.,   4.]),\n",
              " array([  2.        ,   2.42992126,   2.85984252, ..., 547.14015748,\n",
              "        547.57007874, 548.        ]),\n",
              " <a list of 1270 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count the number of patents for each cpc_code"
      ],
      "metadata": {
        "id": "2EZi48ItC0_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "cpc_code_count = dict(zip(cpc_codes_upto_subclass_df.index, [0 for x in range(0,len(cpc_codes_upto_subclass_df.index))]))\n",
        "\n",
        "for cpc_code in cpc_code_dict.keys():\n",
        "    \n",
        "    cpc_code_count[cpc_code_dict[cpc_code]] = len(patent_data_df[patent_data_df['group_id'] == cpc_code].index)\n",
        "    \n",
        "plt.plot(cpc_code_count.keys(), cpc_code_count.values())\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:24.158177Z",
          "iopub.execute_input": "2022-10-17T22:51:24.158888Z",
          "iopub.status.idle": "2022-10-17T22:51:24.167023Z",
          "shell.execute_reply.started": "2022-10-17T22:51:24.158844Z",
          "shell.execute_reply": "2022-10-17T22:51:24.165930Z"
        },
        "trusted": true,
        "id": "-sy3j6E9Ktpm",
        "outputId": "1f1e44ef-a59f-4fca-cc60-82d4d22b6c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ncpc_code_count = dict(zip(cpc_codes_upto_subclass_df.index, [0 for x in range(0,len(cpc_codes_upto_subclass_df.index))]))\\n\\nfor cpc_code in cpc_code_dict.keys():\\n    \\n    cpc_code_count[cpc_code_dict[cpc_code]] = len(patent_data_df[patent_data_df['group_id'] == cpc_code].index)\\n    \\nplt.plot(cpc_code_count.keys(), cpc_code_count.values())\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Validation Split"
      ],
      "metadata": {
        "id": "xcwSBA60Ktpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================================\n",
        "# train_test_split does not work if the \"stratify\" input has any label with only a single occurence\n",
        "# So, we need to repeat those rows which have CPC codes with just a single occurence\n",
        "# =================================================================================================\n",
        "s = patent_data_df['section_id'].value_counts()\n",
        "freq_1_s = s[s == 1]\n",
        "for section in freq_1_s.index:\n",
        "    s2 = patent_data_df[patent_data_df['section_id'] == section]\n",
        "    patent_data_df = pd.concat([patent_data_df, s2], ignore_index = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:24.168337Z",
          "iopub.execute_input": "2022-10-17T22:51:24.169114Z",
          "iopub.status.idle": "2022-10-17T22:51:24.379944Z",
          "shell.execute_reply.started": "2022-10-17T22:51:24.169079Z",
          "shell.execute_reply": "2022-10-17T22:51:24.379088Z"
        },
        "trusted": true,
        "id": "4iCZt9k-Ktpm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_df, test_df = train_test_split(patent_data_df, test_size=0.20, stratify = patent_data_df['section_id'])\n",
        "train_df, valid_df = train_test_split(train_val_df, test_size=0.25, stratify = train_val_df['section_id'])\n",
        "\n",
        "train_df.reset_index(inplace = True)\n",
        "valid_df.reset_index(inplace = True)\n",
        "test_df.reset_index(inplace = True)\n",
        "\n",
        "train_df = train_df.groupby(['id', 'title'], sort = False, as_index = False).agg({'section_id':list})\n",
        "valid_df = valid_df.groupby(['id', 'title'], sort = False, as_index = False).agg({'section_id':list})\n",
        "test_df = test_df.groupby(['id', 'title'], sort = False, as_index = False).agg({'section_id':list})\n",
        "\n",
        "del train_val_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-17T22:51:24.381236Z",
          "iopub.execute_input": "2022-10-17T22:51:24.381660Z",
          "iopub.status.idle": "2022-10-17T22:52:19.716286Z",
          "shell.execute_reply.started": "2022-10-17T22:51:24.381622Z",
          "shell.execute_reply": "2022-10-17T22:52:19.715265Z"
        },
        "trusted": true,
        "id": "hVxZz8hwKtpn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run a sample input through the BERT for Patents model"
      ],
      "metadata": {
        "id": "YdK5TxBMC0_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(CFG.BERT_FOR_PATENTS_PATH)\n",
        "CFG.tokenizer = tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-17T22:52:19.717683Z",
          "iopub.execute_input": "2022-10-17T22:52:19.718095Z",
          "iopub.status.idle": "2022-10-17T22:52:19.819876Z",
          "shell.execute_reply.started": "2022-10-17T22:52:19.718057Z",
          "shell.execute_reply": "2022-10-17T22:52:19.818999Z"
        },
        "trusted": true,
        "id": "v9YPZ_esKtpn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "config = AutoConfig.from_pretrained(CFG.BERT_FOR_PATENTS_PATH)\n",
        "config.max_position_embeddings = CFG.MAX_TOKEN_LEN\n",
        "model_bert_for_patents = AutoModel.from_pretrained(CFG.BERT_FOR_PATENTS_PATH, config = config, ignore_mismatched_sizes=True)\n",
        "\n",
        "sent = [\"This is a patent\", \"Hello all\"]\n",
        "tokenized_sent = tokenizer(sent, truncation = True, add_special_tokens=True, max_length=CFG.MAX_TOKEN_LEN, padding=\"max_length\",\n",
        "                           return_offsets_mapping=False, return_tensors = \"pt\")\n",
        "out = model_bert_for_patents(**tokenized_sent)\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "WqloBp8DC0_P",
        "outputId": "8596855c-b057-4f5e-f629-06cd481d26fe",
        "execution": {
          "iopub.status.busy": "2022-10-17T22:52:19.823321Z",
          "iopub.execute_input": "2022-10-17T22:52:19.823664Z",
          "iopub.status.idle": "2022-10-17T22:52:19.831040Z",
          "shell.execute_reply.started": "2022-10-17T22:52:19.823638Z",
          "shell.execute_reply": "2022-10-17T22:52:19.829985Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nconfig = AutoConfig.from_pretrained(CFG.BERT_FOR_PATENTS_PATH)\\nconfig.max_position_embeddings = CFG.MAX_TOKEN_LEN\\nmodel_bert_for_patents = AutoModel.from_pretrained(CFG.BERT_FOR_PATENTS_PATH, config = config, ignore_mismatched_sizes=True)\\n\\nsent = [\"This is a patent\", \"Hello all\"]\\ntokenized_sent = tokenizer(sent, truncation = True, add_special_tokens=True, max_length=CFG.MAX_TOKEN_LEN, padding=\"max_length\",\\n                           return_offsets_mapping=False, return_tensors = \"pt\")\\nout = model_bert_for_patents(**tokenized_sent)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Custom Dataset"
      ],
      "metadata": {
        "id": "R0mEO5oIC0_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatentClassification_TrainDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, cfg, cpc_code_section_dict, df):\n",
        "        super(PatentClassification_TrainDataset).__init__()\n",
        "        self.cfg = cfg\n",
        "        self.cpc_code_section_dict = cpc_code_section_dict\n",
        "        self.df = df\n",
        "        \n",
        "    def prepare_input(self, batch_num):\n",
        "        \n",
        "        start_idx = min(batch_num * self.cfg.BATCH_SIZE, len(self.df.index)-1)\n",
        "        end_idx = min(start_idx + self.cfg.BATCH_SIZE - 1, len(self.df.index) - 1)\n",
        "       \n",
        "        inputs = self.cfg.tokenizer(list(self.df.loc[start_idx: end_idx, 'title']), truncation = True, add_special_tokens=True, \n",
        "                                    max_length=self.cfg.MAX_TOKEN_LEN, padding = 'longest')\n",
        "        \n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = torch.tensor(v, dtype=torch.long)\n",
        "            \n",
        "        labels = torch.zeros(end_idx - start_idx + 1, self.cfg.NUM_CLASSES, dtype = torch.float)\n",
        "        for i in range(labels.size(0)):\n",
        "            indices = torch.tensor(list(map(self.cpc_code_section_dict.__getitem__, self.df.loc[i+start_idx, 'section_id'])))\n",
        "            labels[i].index_fill_(dim = -1, index = indices, value = 1.0)         \n",
        "            \n",
        "        return inputs, labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df.index)\n",
        "    \n",
        "    def __getitem__(self, batch_num):\n",
        "        \n",
        "        inputs, labels = self.prepare_input(batch_num)\n",
        "        \n",
        "        return inputs, labels\n",
        "    \n",
        "'''\n",
        "data_collator = DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding = 'longest')    \n",
        "def custom_collate_fn(batch):\n",
        "    \n",
        "    for idx, this_batch in enumerate(batch):\n",
        "        inputs, labels = this_batch\n",
        "        if idx != 0:\n",
        "            inputs_dict_list.append(inputs)\n",
        "            labels_list = torch.cat((labels_list, labels), dim=0)\n",
        "        else:\n",
        "            inputs_dict_list = [inputs]\n",
        "            labels_list = labels\n",
        "           \n",
        "    padded_input_dict_list = data_collator(inputs_dict_list)\n",
        "    \n",
        "    return padded_input_dict_list, labels_list\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-17T22:52:19.832786Z",
          "iopub.execute_input": "2022-10-17T22:52:19.833410Z",
          "iopub.status.idle": "2022-10-17T22:52:19.848925Z",
          "shell.execute_reply.started": "2022-10-17T22:52:19.833373Z",
          "shell.execute_reply": "2022-10-17T22:52:19.847924Z"
        },
        "trusted": true,
        "id": "Oxwerp8OKtpo",
        "outputId": "a5051403-eb9d-4871-dd13-a2a3249c21f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndata_collator = DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding = 'longest')    \\ndef custom_collate_fn(batch):\\n    \\n    for idx, this_batch in enumerate(batch):\\n        inputs, labels = this_batch\\n        if idx != 0:\\n            inputs_dict_list.append(inputs)\\n            labels_list = torch.cat((labels_list, labels), dim=0)\\n        else:\\n            inputs_dict_list = [inputs]\\n            labels_list = labels\\n           \\n    padded_input_dict_list = data_collator(inputs_dict_list)\\n    \\n    return padded_input_dict_list, labels_list\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Custom Model"
      ],
      "metadata": {
        "id": "TNRQy4gPC0_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatentClassificationModel(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.model_config = AutoConfig.from_pretrained(self.cfg.BERT_FOR_PATENTS_PATH, output_hidden_states=False)\n",
        "        self.model_config.max_position_embeddings = CFG.MAX_TOKEN_LEN\n",
        "        self.model = AutoModel.from_pretrained(self.cfg.BERT_FOR_PATENTS_PATH, config = self.model_config, ignore_mismatched_sizes=True) \n",
        "        '''\n",
        "        self.attention = torch.nn.Sequential(torch.nn.Linear(self.model_config.hidden_size, self.cfg.ATTENTION_INTERMEDIATE_SIZE),\n",
        "                                             torch.nn.Tanh(),\n",
        "                                             torch.nn.Linear(self.cfg.ATTENTION_INTERMEDIATE_SIZE, 1),\n",
        "                                            torch.nn.Softmax(dim=1))\n",
        "        self.fc_dropout = torch.nn.Dropout(self.cfg.DROPOUT_PROB)\n",
        "        '''\n",
        "        self.fc = torch.nn.Linear(self.model_config.hidden_size, self.cfg.NUM_CLASSES)\n",
        "        self._init_weights(self.fc)\n",
        "        \n",
        "        \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, torch.nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, torch.nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        #one abstract can have multiple cpc codes, hence pass a list of cpc codes for each abstract\n",
        "        model_outputs = self.model(**inputs)\n",
        "        outputs = model_outputs.pooler_output\n",
        "        outputs = self.fc(outputs)\n",
        "        return outputs\n",
        "        "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-17T22:52:19.850588Z",
          "iopub.execute_input": "2022-10-17T22:52:19.851522Z",
          "iopub.status.idle": "2022-10-17T22:52:19.863320Z",
          "shell.execute_reply.started": "2022-10-17T22:52:19.851487Z",
          "shell.execute_reply": "2022-10-17T22:52:19.862418Z"
        },
        "trusted": true,
        "id": "ZQQ9TC1bKtpo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PatentClassification_TrainDataset(CFG, cpc_code_section_dict, train_df)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = None)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-10-17T22:52:19.864590Z",
          "iopub.execute_input": "2022-10-17T22:52:19.865067Z",
          "iopub.status.idle": "2022-10-17T22:52:19.876026Z",
          "shell.execute_reply.started": "2022-10-17T22:52:19.865032Z",
          "shell.execute_reply": "2022-10-17T22:52:19.875108Z"
        },
        "trusted": true,
        "id": "zbALQ33vKtpp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "oO3ENUylC0_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "        \n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
        "    #param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_parameters = [\n",
        "        {'params': [p for n, p in model.model.named_parameters() if (not any(nd in n for nd in no_decay)) and p.requires_grad],\n",
        "         'lr': encoder_lr, 'weight_decay': weight_decay},\n",
        "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and p.requires_grad],\n",
        "         'lr': encoder_lr, 'weight_decay': 0.0},\n",
        "        {'params': [p for n, p in model.named_parameters() if (\"model\" not in n) and p.requires_grad],\n",
        "         'lr': decoder_lr, 'weight_decay': 0.0}\n",
        "    ]\n",
        "    return optimizer_parameters\n",
        "\n",
        "\n",
        "    \n",
        "# ====================================================\n",
        "# scheduler\n",
        "# ====================================================\n",
        "def get_scheduler(cfg, optimizer, num_train_steps):\n",
        "    if cfg.SCHEDULER == 'linear':\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS, num_training_steps=num_train_steps\n",
        "        )\n",
        "    elif cfg.SCHEDULER == 'cosine':\n",
        "        scheduler = get_cosine_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS, num_training_steps=num_train_steps, num_cycles=cfg.NUM_CYCLES\n",
        "        )\n",
        "    return scheduler\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# Function to calculate loss\n",
        "# ====================================================\n",
        "def get_loss(preds, labels, criterion):\n",
        "    with torch.autocast(device_type = device.type):\n",
        "        loss = criterion(preds.view(-1, 1), labels.view(-1, 1))  \n",
        "        loss = loss.item()\n",
        "    return loss\n",
        "    \n",
        "\n",
        "def train_fn(train_dataloader, num_batches, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    \n",
        "    model.train()\n",
        "    #scaler = torch.cuda.amp.GradScaler()\n",
        "    loss_info = AverageMeter()\n",
        "    start = end = time.time()\n",
        "    \n",
        "    for idx, batch in enumerate(train_dataloader):\n",
        "                \n",
        "        inputs, labels = batch\n",
        "        \n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        batch_size = labels.size(0)\n",
        "        \n",
        "        \n",
        "        with torch.autocast(device_type = device.type):\n",
        "            #model_run_start = time.time()\n",
        "            outputs = model(inputs)\n",
        "            #model_run_end = time.time()\n",
        "            #print(\"Model run time: \", model_run_end - model_run_start, \" s\")\n",
        "            loss = criterion(outputs.view(-1, 1), labels.view(-1, 1))\n",
        "            \n",
        "        loss_info.update(loss.item(), batch_size)\n",
        "        \n",
        "        \n",
        "        # Calculate and scale gradients\n",
        "        #scaler.scale(loss).backward()\n",
        "        #backprop_run_start = time.time()\n",
        "        loss.backward()\n",
        "        #backprop_run_end = time.time()\n",
        "        #print(\"Backprop step time: \", backprop_run_end - backprop_run_start, \" s\")\n",
        "        \n",
        "        #grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.MAX_GRAD_NORM)\n",
        "        grad_norm = 0\n",
        "        \n",
        "        \n",
        "        # Update Weights and Biases, Scaler\n",
        "        #scaler.step(optimizer)\n",
        "        #optimizer_run_start = time.time()\n",
        "        optimizer.step()\n",
        "        #optimizer_run_end = time.time()\n",
        "        #print(\"Optimizer step time: \", optimizer_run_end - optimizer_run_start, \" s\")\n",
        "        \n",
        "        #scaler.update()\n",
        "        \n",
        "        #Update Scheduler\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Set all gradients to 0\n",
        "        optimizer.zero_grad(set_to_none = True)\n",
        "        \n",
        " \n",
        "        \n",
        "        if idx % CFG.PRINT_FREQ == 0 or idx == num_batches - 1:\n",
        "            print('Epoch: [{0}][{1}/{2}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  'Grad (Invalid): {grad_norm:.4f}  '\n",
        "                  'LR: {lr:.8f}  '\n",
        "                  .format(epoch+1, idx, num_batches, \n",
        "                          remain=timeSince(start, float(idx+1)/num_batches),\n",
        "                          loss=loss_info,\n",
        "                          grad_norm=grad_norm,\n",
        "                          lr=scheduler.get_lr()[0]))\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    return loss_info.avg\n",
        "\n",
        "def valid_fn(valid_dataloader, num_batches, model, criterion, epoch, device):\n",
        "    \n",
        "    model.eval()\n",
        "    loss_info = AverageMeter()\n",
        "    start = end = time.time()\n",
        "    \n",
        "    for idx, batch in enumerate(valid_dataloader):\n",
        "                \n",
        "        inputs, labels = batch\n",
        "        \n",
        "        batch_size = labels.size(0)\n",
        "        \n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        \n",
        "        with torch.autocast(device_type = device.type):\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "            loss = criterion(outputs.view(-1, 1), labels.view(-1, 1))      \n",
        "                    \n",
        "        loss_info.update(loss.item(), batch_size)\n",
        "        try:\n",
        "            preds_concat = torch.cat((preds_concat, outputs), dim = 0)\n",
        "            labels_concat = torch.cat((labels_concat, labels), dim = 0)\n",
        "        except:    \n",
        "            preds_concat = outputs\n",
        "            labels_concat = labels\n",
        "        \n",
        "        if idx % CFG.PRINT_FREQ == 0 or idx == num_batches - 1:\n",
        "            print('Epoch: [{0}][{1}/{2}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  .format(epoch+1, idx, num_batches, \n",
        "                          remain=timeSince(start, float(idx+1)/num_batches),\n",
        "                          loss=loss_info))\n",
        "        \n",
        "        \n",
        "        overall_val_loss = get_loss(preds_concat, labels_concat, criterion)\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        return overall_val_loss"
      ],
      "metadata": {
        "id": "R3vv8eHfC0_S",
        "execution": {
          "iopub.status.busy": "2022-10-17T22:52:19.877422Z",
          "iopub.execute_input": "2022-10-17T22:52:19.878342Z",
          "iopub.status.idle": "2022-10-17T22:52:19.904270Z",
          "shell.execute_reply.started": "2022-10-17T22:52:19.878306Z",
          "shell.execute_reply": "2022-10-17T22:52:19.903137Z"
        },
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "metadata": {
        "id": "tg78r61EC0_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop():\n",
        "        \n",
        "    model = PatentClassificationModel(CFG)\n",
        "    model.to(device)\n",
        "    \n",
        "    #optimizer_parameters = get_optimizer_params(model,encoder_lr=CFG.ENCODER_LR,decoder_lr=CFG.DECODER_LR,weight_decay=CFG.WEIGHT_DECAY)\n",
        "    optimizer_parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "    \n",
        "    optimizer = AdamW(optimizer_parameters, lr=CFG.ENCODER_LR, eps=CFG.EPS, betas=CFG.BETAS)\n",
        "    \n",
        "    num_train_batches = len(train_df)// CFG.BATCH_SIZE\n",
        "    num_val_batches = len(valid_df)// CFG.BATCH_SIZE\n",
        "    num_train_steps = num_train_batches * CFG.NUM_EPOCHS\n",
        "    \n",
        "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
        "    \n",
        "    # ====================================================\n",
        "    # loop\n",
        "    # ====================================================\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
        "    \n",
        "    best_loss = CFG.INFINITY\n",
        "    best_epoch = 0\n",
        "    \n",
        "    train_dataset = PatentClassification_TrainDataset(CFG, cpc_code_section_dict, train_df)\n",
        "    valid_dataset = PatentClassification_TrainDataset(CFG, cpc_code_section_dict, valid_df)\n",
        "    \n",
        "    #num_workers = 2 gives best speed (for GPU)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size = None, num_workers = 2) \n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size = None, num_workers = 2) \n",
        "    \n",
        "    \n",
        "    for epoch in range(CFG.NUM_EPOCHS):   \n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        #train\n",
        "        avg_train_loss = train_fn(train_dataloader, num_train_batches, model, criterion, optimizer, epoch, scheduler, device)\n",
        "        \n",
        "        #eval\n",
        "        overall_val_loss = valid_fn(valid_dataloader, num_val_batches, model, criterion, epoch, device)\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}, overall_val_loss: {overall_val_loss: 4f} time: {elapsed:.0f}s\")\n",
        "        torch.save({'model': model.state_dict()}, f\"BERT_For_Patents_FineTuned_{epoch+1}.pth\")\n",
        "            \n",
        "        if overall_val_loss < best_loss:\n",
        "            best_loss = overall_val_loss\n",
        "            best_epoch = epoch + 1\n",
        "            torch.save({'model': model.state_dict()}, \"BERT_For_Patents_FineTuned.pth\")\n",
        "            \n",
        "    print(f'Best Epoch {best_epoch} - Best Loss: {best_loss:.4f}')\n",
        "            \n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "              "
      ],
      "metadata": {
        "id": "tVEz812xC0_S",
        "execution": {
          "iopub.status.busy": "2022-10-17T22:52:19.907426Z",
          "iopub.execute_input": "2022-10-17T22:52:19.907686Z",
          "iopub.status.idle": "2022-10-17T22:52:19.920878Z",
          "shell.execute_reply.started": "2022-10-17T22:52:19.907663Z",
          "shell.execute_reply": "2022-10-17T22:52:19.919973Z"
        },
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    \n",
        "    if CFG.F_TRAIN:\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        train_loop()\n",
        "        "
      ],
      "metadata": {
        "id": "oKG0pRqtC0_T",
        "outputId": "f7c59f53-abe2-4adc-92a6-e8aff9b1c320",
        "execution": {
          "iopub.status.busy": "2022-10-17T22:52:19.922327Z",
          "iopub.execute_input": "2022-10-17T22:52:19.922805Z",
          "iopub.status.idle": "2022-10-17T22:54:22.279098Z",
          "shell.execute_reply.started": "2022-10-17T22:52:19.922772Z",
          "shell.execute_reply": "2022-10-17T22:54:22.276106Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Inputs/bert-for-patents-pytorch were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at /content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Inputs/bert-for-patents-pytorch and are newly initialized because the shapes did not match:\n",
            "- bert.embeddings.position_ids: found shape torch.Size([1, 512]) in the checkpoint and torch.Size([1, 128]) in the model instantiated\n",
            "- bert.embeddings.position_embeddings.weight: found shape torch.Size([512, 1024]) in the checkpoint and torch.Size([128, 1024]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/43680] Elapsed 0m 2s (remain 1492m 33s) Loss: 0.6948(0.6948) Grad: 4.6618  LR: 0.00002000  \n",
            "Epoch: [1][50/43680] Elapsed 0m 26s (remain 374m 41s) Loss: 0.4114(0.4265) Grad: 0.4051  LR: 0.00002000  \n",
            "Epoch: [1][100/43680] Elapsed 0m 53s (remain 384m 34s) Loss: 0.4339(0.4178) Grad: 0.5891  LR: 0.00001999  \n",
            "Epoch: [1][150/43680] Elapsed 1m 20s (remain 385m 45s) Loss: 0.4346(0.4141) Grad: 0.3535  LR: 0.00001999  \n",
            "Epoch: [1][200/43680] Elapsed 1m 45s (remain 380m 58s) Loss: 0.4132(0.4120) Grad: 0.5673  LR: 0.00001998  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-00cfca78fcad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-df72367e1271>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-c04dac2d229d>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_dataloader, num_batches, model, criterion, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m#print(\"Backprop step time: \", backprop_run_end - backprop_run_start, \" s\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_GRAD_NORM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;31m#grad_norm = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise RuntimeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         raise RuntimeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \"\"\"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gx8HH0lJKtpq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}