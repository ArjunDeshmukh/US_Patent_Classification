{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Check if the code is running in colab","metadata":{}},{"cell_type":"code","source":"try:\n    import google.colab\n    IN_COLAB = True\nexcept:\n    IN_COLAB = False","metadata":{"id":"6x774kWbGeJI","execution":{"iopub.status.busy":"2022-10-28T14:20:54.823432Z","iopub.execute_input":"2022-10-28T14:20:54.824434Z","iopub.status.idle":"2022-10-28T14:20:54.847293Z","shell.execute_reply.started":"2022-10-28T14:20:54.824303Z","shell.execute_reply":"2022-10-28T14:20:54.846360Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"if IN_COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')","metadata":{"id":"69ZldWGCDQ7n","outputId":"f943f633-c840-4145-d57e-ef7dea037e65","execution":{"iopub.status.busy":"2022-10-28T14:20:54.849211Z","iopub.execute_input":"2022-10-28T14:20:54.849713Z","iopub.status.idle":"2022-10-28T14:20:54.855286Z","shell.execute_reply.started":"2022-10-28T14:20:54.849675Z","shell.execute_reply":"2022-10-28T14:20:54.854275Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if IN_COLAB:\n    !pip install transformers","metadata":{"id":"PjYyyi9tGGEL","outputId":"ab9fdc41-7ee5-44af-8ac6-83e29d7731a9","execution":{"iopub.status.busy":"2022-10-28T14:20:54.857226Z","iopub.execute_input":"2022-10-28T14:20:54.857879Z","iopub.status.idle":"2022-10-28T14:20:54.864680Z","shell.execute_reply.started":"2022-10-28T14:20:54.857822Z","shell.execute_reply":"2022-10-28T14:20:54.863701Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Importing Libraries\n","metadata":{"id":"83YXgK8eC0_B"}},{"cell_type":"code","source":"import requests\nimport json\nimport sys\nimport pandas as pd\nimport os.path\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math\n\nimport time\nfrom tqdm import tqdm\n\nfrom google.cloud import bigquery\nfrom google.oauth2 import service_account\n\nfrom transformers import AutoModelForMaskedLM\nfrom transformers import AutoModel, AutoConfig, AutoTokenizer, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, DataCollatorWithPadding\n\nimport torch\nfrom torch.profiler import profile, record_function, ProfilerActivity\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import Dataset, DataLoader, IterableDataset\nfrom torch.nn.utils.rnn import pad_sequence\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")   \n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device: \", device)\n\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nfrom sys import getsizeof\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"e7bR6yPtC0_E","outputId":"d928b6c6-83c0-4e0a-e2ff-02c64bc31f85","execution":{"iopub.status.busy":"2022-10-28T14:20:54.866799Z","iopub.execute_input":"2022-10-28T14:20:54.867531Z","iopub.status.idle":"2022-10-28T14:21:02.103650Z","shell.execute_reply.started":"2022-10-28T14:20:54.867498Z","shell.execute_reply":"2022-10-28T14:21:02.102558Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Device:  cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Define configuration constants","metadata":{"id":"FZvI20qjC0_G"}},{"cell_type":"code","source":"class CFG:\n    CPC_CODES_PATH = \"../input/cpc-code-upto-subclass/CPC_codes_upto_subclass.csv\"\n    PATENTS_DATA_PATH = \"../input/us-patents-abstracts-cpc/US_Patents_Abstracts_CPC_Section.csv\"\n    BERT_FOR_PATENTS_PATH = \"../input/bert-for-patents/bert-for-patents-pytorch\"\n    TRAINED_MODEL_PATH = \"../input/patentclassificationmodels/BERT_For_Patents_FineTuned_3.pth\"\n    OUTPUT_DIR = \"./\"\n    MAX_TOKEN_LEN = 512\n    DROPOUT_PROB = 0.1\n    ATTENTION_INTERMEDIATE_SIZE = 512\n    GOOGLE_CLOUD_CRED_JSON = '../input/googlecloudcred/us-patent-classification-d344a6ddc702.json'\n    GOOGLE_CLOUD_PROJ_ID = 'us-patent-classification'\n    BATCH_SIZE = 64\n    NUM_EPOCHS = 5\n    TRAIN_PATENT_START_YEAR = 2001\n    TRAIN_PATENT_END_YEAR = 2018\n    TEST_PATENT_START_YEAR = 2019\n    TEST_PATENT_END_YEAR = 2022\n    NUM_FOLDS = 6 #Total number of years used for training should be divisible by this number\n    ENCODER_LR = 1e-3\n    DECODER_LR = 2e-5\n    MIN_LR = 1e-6\n    EPS = 1e-8\n    WEIGHT_DECAY = 0.01\n    SCHEDULER = 'linear'\n    NUM_WARMUP_STEPS = 0\n    NUM_CYCLES = 0.5\n    BETAS=(0.9, 0.999)\n    MAX_GRAD_NORM = 1000\n    PRINT_FREQ = 1000\n    INFINITY = 1e6\n    F_TRAIN = 1\n    MID_EPOCH_SAVE_PERCENT = 0.5\n  \n  # Parameters which will be added in subsequent code:\n  # NUM_CLASSES, TRAIN_NUM_PATENTS\n\nif IN_COLAB:\n    CFG.CPC_CODES_PATH = \"/content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Inputs/cpc-code-upto-subclass/CPC_codes_upto_subclass.csv\"\n    CFG.PATENTS_DATA_PATH = \"/content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Inputs/us-patents-cpc-text/US_Patents_Abstracts_CPC_Section.csv\"\n    CFG.BERT_FOR_PATENTS_PATH = \"/content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Inputs/bert-for-patents-pytorch\"\n    CFG.GOOGLE_CLOUD_CRED_JSON = \"/content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Inputs/googlecloudcred/us-patent-classification-d344a6ddc702.json\"\n    CFG.OUTPUT_DIR = \"/content/drive/MyDrive/MachineLearning/ML_Deployment/Patent_Class_Outputs/\"","metadata":{"id":"TnAfPfmSC0_G","execution":{"iopub.status.busy":"2022-10-28T14:21:02.107016Z","iopub.execute_input":"2022-10-28T14:21:02.107503Z","iopub.status.idle":"2022-10-28T14:21:02.115814Z","shell.execute_reply.started":"2022-10-28T14:21:02.107473Z","shell.execute_reply":"2022-10-28T14:21:02.114670Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### List of CPC codes","metadata":{"id":"07hZ1QpUC0_H"}},{"cell_type":"code","source":"cpc_codes_upto_subclass_df = pd.read_csv(CFG.CPC_CODES_PATH)\ncpc_codes_upto_subclass_df.head()\nnum_codes = len(pd.unique(cpc_codes_upto_subclass_df['code']))\nsections = pd.unique(cpc_codes_upto_subclass_df['section'])\ndf_len = len(cpc_codes_upto_subclass_df)\n\nprint(\"Number of rows in dataframe: \", df_len, \"\\n\")\nprint(\"Number of CPC codes upto subclass: \", num_codes)\ncpc_code_dict = dict(zip(cpc_codes_upto_subclass_df['code'].values, cpc_codes_upto_subclass_df.index))\ncpc_code_section_dict = dict(zip(sections, range(len(sections))))\n\nCFG.NUM_CLASSES = len(sections)","metadata":{"id":"v_Bg2DLLC0_H","outputId":"1eb7192d-b9f8-4f2a-d53b-b897d3c8f66e","execution":{"iopub.status.busy":"2022-10-28T14:21:02.117609Z","iopub.execute_input":"2022-10-28T14:21:02.118619Z","iopub.status.idle":"2022-10-28T14:21:02.154953Z","shell.execute_reply.started":"2022-10-28T14:21:02.118539Z","shell.execute_reply":"2022-10-28T14:21:02.153901Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of rows in dataframe:  674 \n\nNumber of CPC codes upto subclass:  674\n","output_type":"stream"}]},{"cell_type":"code","source":"cpc_code_section_dict","metadata":{"execution":{"iopub.status.busy":"2022-10-28T14:21:02.157587Z","iopub.execute_input":"2022-10-28T14:21:02.157965Z","iopub.status.idle":"2022-10-28T14:21:02.166337Z","shell.execute_reply.started":"2022-10-28T14:21:02.157930Z","shell.execute_reply":"2022-10-28T14:21:02.165243Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'Y': 8}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Dowloaded Patent Data","metadata":{"id":"FXdNeO0NKtpl"}},{"cell_type":"code","source":"patent_data_df = pd.read_csv(CFG.PATENTS_DATA_PATH)\npatent_data_df.drop(columns = ['Unnamed: 0'], inplace = True)\nlen(patent_data_df)","metadata":{"id":"fH_pzGHjKtpl","execution":{"iopub.status.busy":"2022-10-28T14:21:02.167841Z","iopub.execute_input":"2022-10-28T14:21:02.168825Z","iopub.status.idle":"2022-10-28T14:22:32.852464Z","shell.execute_reply.started":"2022-10-28T14:21:02.168791Z","shell.execute_reply":"2022-10-28T14:22:32.851548Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"5971892"},"metadata":{}}]},{"cell_type":"code","source":"patent_data_df.drop_duplicates(inplace = True)\nlen(patent_data_df)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T14:22:32.853902Z","iopub.execute_input":"2022-10-28T14:22:32.854242Z","iopub.status.idle":"2022-10-28T14:22:41.907987Z","shell.execute_reply.started":"2022-10-28T14:22:32.854215Z","shell.execute_reply":"2022-10-28T14:22:41.907099Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"3797258"},"metadata":{}}]},{"cell_type":"code","source":"section_instances = patent_data_df['section_id'].value_counts()\nplt.plot(section_instances)\nprint(max(section_instances)/min(section_instances))","metadata":{"execution":{"iopub.status.busy":"2022-10-28T14:22:41.918685Z","iopub.execute_input":"2022-10-28T14:22:41.918981Z","iopub.status.idle":"2022-10-28T14:22:42.262412Z","shell.execute_reply.started":"2022-10-28T14:22:41.918954Z","shell.execute_reply":"2022-10-28T14:22:42.261435Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"38.24521330198186\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"### Count the number of patents for each cpc_code","metadata":{"id":"2EZi48ItC0_L"}},{"cell_type":"code","source":"'''\ncpc_code_count = dict(zip(cpc_codes_upto_subclass_df.index, [0 for x in range(0,len(cpc_codes_upto_subclass_df.index))]))\n\nfor cpc_code in cpc_code_dict.keys():\n    \n    cpc_code_count[cpc_code_dict[cpc_code]] = len(patent_data_df[patent_data_df['group_id'] == cpc_code].index)\n    \nplt.plot(cpc_code_count.keys(), cpc_code_count.values())\n\n'''\n","metadata":{"id":"-sy3j6E9Ktpm","outputId":"e4236c00-59aa-4fcc-8030-141f90704500","execution":{"iopub.status.busy":"2022-10-28T14:22:42.264163Z","iopub.execute_input":"2022-10-28T14:22:42.266664Z","iopub.status.idle":"2022-10-28T14:22:42.274778Z","shell.execute_reply.started":"2022-10-28T14:22:42.266635Z","shell.execute_reply":"2022-10-28T14:22:42.273907Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"\"\\ncpc_code_count = dict(zip(cpc_codes_upto_subclass_df.index, [0 for x in range(0,len(cpc_codes_upto_subclass_df.index))]))\\n\\nfor cpc_code in cpc_code_dict.keys():\\n    \\n    cpc_code_count[cpc_code_dict[cpc_code]] = len(patent_data_df[patent_data_df['group_id'] == cpc_code].index)\\n    \\nplt.plot(cpc_code_count.keys(), cpc_code_count.values())\\n\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"### Train Validation Split","metadata":{"id":"xcwSBA60Ktpm"}},{"cell_type":"code","source":"# ================================================================================================\n# train_test_split does not work if the \"stratify\" input has any label with only a single occurence\n# So, we need to repeat those rows which have CPC codes with just a single occurence\n# =================================================================================================\ns = patent_data_df['section_id'].value_counts()\nfreq_1_s = s[s == 1]\nfor section in freq_1_s.index:\n    s2 = patent_data_df[patent_data_df['section_id'] == section]\n    patent_data_df = pd.concat([patent_data_df, s2], ignore_index = True)","metadata":{"id":"4iCZt9k-Ktpm","execution":{"iopub.status.busy":"2022-10-28T14:22:42.278022Z","iopub.execute_input":"2022-10-28T14:22:42.278284Z","iopub.status.idle":"2022-10-28T14:22:42.405468Z","shell.execute_reply.started":"2022-10-28T14:22:42.278260Z","shell.execute_reply":"2022-10-28T14:22:42.404440Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_val_df, test_df = train_test_split(patent_data_df, test_size=(1.0/3.0), stratify = patent_data_df['section_id'])\ntrain_df, valid_df = train_test_split(train_val_df, test_size=(1.0/2.0), stratify = train_val_df['section_id'])\n_, valid_df = train_test_split(valid_df, test_size=(1.0/2.0), stratify = valid_df['section_id'])\n\ntrain_df.reset_index(inplace = True)\nvalid_df.reset_index(inplace = True)\ntest_df.reset_index(inplace = True)\n\ntrain_df = train_df.groupby(['id', 'abstract'], sort = False, as_index = False).agg({'section_id':list})\nvalid_df = valid_df.groupby(['id', 'abstract'], sort = False, as_index = False).agg({'section_id':list})\ntest_df = test_df.groupby(['id', 'abstract'], sort = False, as_index = False).agg({'section_id':list})\n\ndel train_val_df","metadata":{"id":"hVxZz8hwKtpn","execution":{"iopub.status.busy":"2022-10-28T14:22:42.409939Z","iopub.execute_input":"2022-10-28T14:22:42.410225Z","iopub.status.idle":"2022-10-28T14:23:14.550611Z","shell.execute_reply.started":"2022-10-28T14:22:42.410200Z","shell.execute_reply":"2022-10-28T14:23:14.549603Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"len(valid_df)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T14:23:14.551985Z","iopub.execute_input":"2022-10-28T14:23:14.552631Z","iopub.status.idle":"2022-10-28T14:23:14.559568Z","shell.execute_reply.started":"2022-10-28T14:23:14.552594Z","shell.execute_reply":"2022-10-28T14:23:14.558427Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"605667"},"metadata":{}}]},{"cell_type":"markdown","source":"### Run a sample input through the BERT for Patents model","metadata":{"id":"YdK5TxBMC0_P"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(CFG.BERT_FOR_PATENTS_PATH)\nCFG.tokenizer = tokenizer","metadata":{"id":"v9YPZ_esKtpn","execution":{"iopub.status.busy":"2022-10-28T14:23:14.560932Z","iopub.execute_input":"2022-10-28T14:23:14.561361Z","iopub.status.idle":"2022-10-28T14:23:14.695547Z","shell.execute_reply.started":"2022-10-28T14:23:14.561328Z","shell.execute_reply":"2022-10-28T14:23:14.694571Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"'''\nconfig = AutoConfig.from_pretrained(CFG.BERT_FOR_PATENTS_PATH)\nconfig.max_position_embeddings = CFG.MAX_TOKEN_LEN\nmodel_bert_for_patents = AutoModel.from_pretrained(CFG.BERT_FOR_PATENTS_PATH, config = config, ignore_mismatched_sizes=True)\n\nsent = [\"This is a patent\", \"Hello all\"]\ntokenized_sent = tokenizer(sent, truncation = True, add_special_tokens=True, max_length=CFG.MAX_TOKEN_LEN, padding=\"max_length\",\n                           return_offsets_mapping=False, return_tensors = \"pt\")\nout = model_bert_for_patents(**tokenized_sent)\n\n'''\n","metadata":{"id":"WqloBp8DC0_P","outputId":"c5acff3a-60bd-43f4-c2c2-19ce3d4157da","execution":{"iopub.status.busy":"2022-10-28T14:23:14.697137Z","iopub.execute_input":"2022-10-28T14:23:14.697494Z","iopub.status.idle":"2022-10-28T14:23:14.704190Z","shell.execute_reply.started":"2022-10-28T14:23:14.697460Z","shell.execute_reply":"2022-10-28T14:23:14.703269Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'\\nconfig = AutoConfig.from_pretrained(CFG.BERT_FOR_PATENTS_PATH)\\nconfig.max_position_embeddings = CFG.MAX_TOKEN_LEN\\nmodel_bert_for_patents = AutoModel.from_pretrained(CFG.BERT_FOR_PATENTS_PATH, config = config, ignore_mismatched_sizes=True)\\n\\nsent = [\"This is a patent\", \"Hello all\"]\\ntokenized_sent = tokenizer(sent, truncation = True, add_special_tokens=True, max_length=CFG.MAX_TOKEN_LEN, padding=\"max_length\",\\n                           return_offsets_mapping=False, return_tensors = \"pt\")\\nout = model_bert_for_patents(**tokenized_sent)\\n\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Build Custom Dataset","metadata":{"id":"R0mEO5oIC0_Q"}},{"cell_type":"code","source":"class PatentClassification_TrainDataset(Dataset):\n    \n    def __init__(self, cfg, cpc_code_section_dict, df):\n        super(PatentClassification_TrainDataset).__init__()\n        self.cfg = cfg\n        self.cpc_code_section_dict = cpc_code_section_dict\n        self.df = df\n        \n    def prepare_input(self, batch_num):\n        \n        start_idx = min(batch_num * self.cfg.BATCH_SIZE, len(self.df.index)-1)\n        end_idx = min(start_idx + self.cfg.BATCH_SIZE - 1, len(self.df.index) - 1)\n       \n        inputs = self.cfg.tokenizer(list(self.df.loc[start_idx: end_idx, 'abstract']), truncation = True, add_special_tokens=True, \n                                    max_length=self.cfg.MAX_TOKEN_LEN, padding = 'longest')\n        \n        for k, v in inputs.items():\n            inputs[k] = torch.tensor(v, dtype=torch.long)\n            \n        labels = torch.zeros(end_idx - start_idx + 1, self.cfg.NUM_CLASSES, dtype = torch.float)\n        for i in range(labels.size(0)):\n            indices = torch.tensor(list(map(self.cpc_code_section_dict.__getitem__, self.df.loc[i+start_idx, 'section_id'])))\n            labels[i].index_fill_(dim = -1, index = indices, value = 1.0)         \n            \n        return inputs, labels\n    \n    def __len__(self):\n        return len(self.df.index)\n    \n    def __getitem__(self, batch_num):\n        \n        inputs, labels = self.prepare_input(batch_num)\n        \n        return inputs, labels\n    \n'''\ndata_collator = DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding = 'longest')    \ndef custom_collate_fn(batch):\n    \n    for idx, this_batch in enumerate(batch):\n        inputs, labels = this_batch\n        if idx != 0:\n            inputs_dict_list.append(inputs)\n            labels_list = torch.cat((labels_list, labels), dim=0)\n        else:\n            inputs_dict_list = [inputs]\n            labels_list = labels\n           \n    padded_input_dict_list = data_collator(inputs_dict_list)\n    \n    return padded_input_dict_list, labels_list\n\n'''","metadata":{"id":"Oxwerp8OKtpo","outputId":"084c3408-03fc-40f8-a5e9-d47c82257761","execution":{"iopub.status.busy":"2022-10-28T14:23:14.705637Z","iopub.execute_input":"2022-10-28T14:23:14.706235Z","iopub.status.idle":"2022-10-28T14:23:14.723094Z","shell.execute_reply.started":"2022-10-28T14:23:14.706199Z","shell.execute_reply":"2022-10-28T14:23:14.722163Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"\\ndata_collator = DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding = 'longest')    \\ndef custom_collate_fn(batch):\\n    \\n    for idx, this_batch in enumerate(batch):\\n        inputs, labels = this_batch\\n        if idx != 0:\\n            inputs_dict_list.append(inputs)\\n            labels_list = torch.cat((labels_list, labels), dim=0)\\n        else:\\n            inputs_dict_list = [inputs]\\n            labels_list = labels\\n           \\n    padded_input_dict_list = data_collator(inputs_dict_list)\\n    \\n    return padded_input_dict_list, labels_list\\n\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"### Build Custom Model","metadata":{"id":"TNRQy4gPC0_R"}},{"cell_type":"code","source":"class PatentClassificationModel(torch.nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.model_config = AutoConfig.from_pretrained(self.cfg.BERT_FOR_PATENTS_PATH, output_hidden_states=False)\n        self.model_config.max_position_embeddings = CFG.MAX_TOKEN_LEN\n        self.model = AutoModel.from_pretrained(self.cfg.BERT_FOR_PATENTS_PATH, config = self.model_config, ignore_mismatched_sizes=True) \n        '''\n        self.attention = torch.nn.Sequential(torch.nn.Linear(self.model_config.hidden_size, self.cfg.ATTENTION_INTERMEDIATE_SIZE),\n                                             torch.nn.Tanh(),\n                                             torch.nn.Linear(self.cfg.ATTENTION_INTERMEDIATE_SIZE, 1),\n                                            torch.nn.Softmax(dim=1))\n        '''\n        self.fc_dropout = torch.nn.Dropout(self.cfg.DROPOUT_PROB)\n        self.fc = torch.nn.Linear(self.model_config.hidden_size, self.cfg.NUM_CLASSES)\n        self._init_weights(self.fc)\n        \n        \n    def _init_weights(self, module):\n        if isinstance(module, torch.nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, torch.nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, torch.nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def forward(self, inputs):\n        #one abstract can have multiple cpc codes, hence pass a list of cpc codes for each abstract\n        model_outputs = self.model(**inputs)\n        outputs = model_outputs.pooler_output\n        outputs = self.fc_dropout(outputs)\n        outputs = self.fc(outputs)\n        return outputs\n        ","metadata":{"id":"ZQQ9TC1bKtpo","execution":{"iopub.status.busy":"2022-10-28T14:23:14.724865Z","iopub.execute_input":"2022-10-28T14:23:14.725735Z","iopub.status.idle":"2022-10-28T14:23:14.738731Z","shell.execute_reply.started":"2022-10-28T14:23:14.725707Z","shell.execute_reply":"2022-10-28T14:23:14.737829Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions","metadata":{"id":"oO3ENUylC0_R"}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        \ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\ndef get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n    #param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {'params': [p for n, p in model.model.named_parameters() if (not any(nd in n for nd in no_decay)) and p.requires_grad],\n         'lr': encoder_lr, 'weight_decay': weight_decay},\n        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and p.requires_grad],\n         'lr': encoder_lr, 'weight_decay': 0.0},\n        {'params': [p for n, p in model.named_parameters() if (\"model\" not in n) and p.requires_grad],\n         'lr': decoder_lr, 'weight_decay': 0.0}\n    ]\n    return optimizer_parameters\n\n\n    \n# ====================================================\n# scheduler\n# ====================================================\ndef get_scheduler(cfg, optimizer, num_train_steps):\n    if cfg.SCHEDULER == 'linear':\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS, num_training_steps=num_train_steps\n        )\n    elif cfg.SCHEDULER == 'cosine':\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS, num_training_steps=num_train_steps, num_cycles=cfg.NUM_CYCLES\n        )\n    return scheduler\n\n\n# ====================================================\n# Function to calculate loss\n# ====================================================\ndef get_loss(preds, labels, criterion):\n    loss = criterion(preds.view(-1, 1), labels.view(-1, 1))  \n    loss = loss.item()\n    return loss\n    \n\ndef train_fn(train_dataloader, num_batches, model, criterion, optimizer, epoch, scheduler, device):\n    \n    model.train()\n    #scaler = torch.cuda.amp.GradScaler()\n    loss_info = AverageMeter()\n    start = end = time.time()\n    \n    print(f\"=========================== Training Model: Epoch {epoch+1} =====================================\")\n    \n    for idx, batch in enumerate(train_dataloader):\n                \n        inputs, labels = batch\n        \n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        labels = labels.to(device)\n        \n        batch_size = labels.size(0)\n        \n        \n        #with torch.autocast(device_type = device.type):\n        #model_run_start = time.time()\n        outputs = model(inputs)\n        #model_run_end = time.time()\n        #print(\"Model run time: \", model_run_end - model_run_start, \" s\")\n        loss = criterion(outputs.view(-1, 1), labels.view(-1, 1))\n            \n        loss_info.update(loss.item(), batch_size)\n        \n        optimizer.zero_grad(set_to_none = False)\n        # Calculate and scale gradients\n        #scaler.scale(loss).backward()\n        #backprop_run_start = time.time()\n        loss.backward()\n        #backprop_run_end = time.time()\n        #print(\"Backprop step time: \", backprop_run_end - backprop_run_start, \" s\")\n        \n        #grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.MAX_GRAD_NORM)\n        grad_norm = 0\n        \n        \n        # Update Weights and Biases, Scaler\n        #scaler.step(optimizer)\n        #optimizer_run_start = time.time()\n        optimizer.step()\n        #optimizer_run_end = time.time()\n        #print(\"Optimizer step time: \", optimizer_run_end - optimizer_run_start, \" s\")\n        \n        #scaler.update()\n        \n        #Update Scheduler\n        scheduler.step()\n        \n        # Set all gradients to 0\n        #optimizer.zero_grad(set_to_none = True)       \n \n        \n        if idx % CFG.PRINT_FREQ == 0 or idx == num_batches - 1:\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad (Invalid): {grad_norm:.4f}  '\n                  'LR: {lr:.8f}  '\n                  .format(epoch+1, idx+1, num_batches, \n                          remain=timeSince(start, float(idx+1)/num_batches),\n                          loss=loss_info,\n                          grad_norm=grad_norm,\n                          lr=scheduler.get_lr()[0]))\n            \n        if idx == int(CFG.MID_EPOCH_SAVE_PERCENT*(num_batches - 1)):\n            torch.save({'model': model.state_dict()}, \n                       CFG.OUTPUT_DIR + f\"BERT_For_Patents_FineTuned_{CFG.MID_EPOCH_SAVE_PERCENT*(2*epoch+1)}.pth\")\n            \n        \n        if idx >= (num_batches - 1):\n            break\n    print(f\"==================================== Epoch {epoch+1} Training Done ===========================================\\n\")\n    \n    return loss_info.avg\n\ndef valid_fn(valid_dataloader, num_batches, model, criterion, epoch, device):\n    \n    model.eval()\n    start = end = time.time()\n    \n    print(f\"=========================== Validating Model Trained on Epoch {epoch+1} =====================================\")\n    \n    for idx, batch in enumerate(valid_dataloader):\n                \n        inputs, labels = batch\n        \n        batch_size = labels.size(0)\n        \n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        labels = labels.to(device)\n        \n        \n        #with torch.autocast(device_type = device.type):\n        with torch.no_grad():\n            outputs = model(inputs)\n        \n        try:\n            preds_concat = torch.cat((preds_concat, outputs), dim = 0)\n            labels_concat = torch.cat((labels_concat, labels), dim = 0)\n        except:    \n            preds_concat = outputs\n            labels_concat = labels\n        \n        if idx % CFG.PRINT_FREQ == 0 or idx == num_batches - 1:\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  .format(epoch+1, idx+1, num_batches, \n                          remain=timeSince(start, float(idx+1)/num_batches)))\n        \n        \n        if idx >= (num_batches - 1):\n            break\n            \n    overall_val_loss = get_loss(preds_concat, labels_concat, criterion)\n    \n    print(f\"==================================== Epoch {epoch+1} Validation Done ===========================================\\n\")\n        \n    return overall_val_loss\n\n\ndef infer_fn(test_dataloader, num_batches, model, criterion, device):\n    \n    model.eval()\n    \n    print(f\"=========================== Testing Trained Model =====================================\")\n    \n    for idx, batch in enumerate(test_dataloader):\n                \n        inputs, labels = batch\n        \n        batch_size = labels.size(0)\n        \n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        labels = labels.to(device)\n        \n        \n        #with torch.autocast(device_type = device.type):\n        with torch.no_grad():\n            outputs = model(inputs)\n\n        try:\n            preds_concat = torch.cat((preds_concat, outputs), dim = 0)\n            labels_concat = torch.cat((labels_concat, labels), dim = 0)\n        except:    \n            preds_concat = outputs\n            labels_concat = labels\n            \n        if idx % CFG.PRINT_FREQ == 0 or idx == num_batches - 1:\n            print(f\"[{idx + 1}/{num_batches}] Batches Done\")\n        \n        \n        if idx >= (num_batches - 1):\n            break\n            \n    overall_test_loss = get_loss(preds_concat, labels_concat, criterion)\n    \n    print(f\"==================================== Testing Done ===========================================\\n\")\n        \n    return overall_test_loss","metadata":{"id":"R3vv8eHfC0_S","execution":{"iopub.status.busy":"2022-10-28T14:23:14.740424Z","iopub.execute_input":"2022-10-28T14:23:14.741120Z","iopub.status.idle":"2022-10-28T14:23:14.773743Z","shell.execute_reply.started":"2022-10-28T14:23:14.741078Z","shell.execute_reply":"2022-10-28T14:23:14.772797Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Training loop","metadata":{"id":"tg78r61EC0_S"}},{"cell_type":"code","source":"def train_loop():\n        \n    model = PatentClassificationModel(CFG)\n    model.to(device)\n    \n    for n, p in model.named_parameters():\n        if n != 'fc.weight' and n != 'fc.bias':\n            p.requires_grad = False\n    \n    \n    #optimizer_parameters = get_optimizer_params(model,encoder_lr=CFG.ENCODER_LR,decoder_lr=CFG.DECODER_LR,weight_decay=CFG.WEIGHT_DECAY)\n    optimizer_parameters = [p for p in model.parameters() if p.requires_grad]\n    \n    optimizer = AdamW(optimizer_parameters, lr=CFG.ENCODER_LR, eps=CFG.EPS, betas=CFG.BETAS)\n    \n    num_train_batches = math.ceil(len(train_df)/CFG.BATCH_SIZE)\n    num_val_batches = math.ceil(len(valid_df)/CFG.BATCH_SIZE)\n    num_train_steps = num_train_batches * CFG.NUM_EPOCHS\n    \n    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n    \n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n    \n    best_loss = CFG.INFINITY\n    best_epoch = 0\n    \n    train_dataset = PatentClassification_TrainDataset(CFG, cpc_code_section_dict, train_df)\n    valid_dataset = PatentClassification_TrainDataset(CFG, cpc_code_section_dict, valid_df)\n    \n    #num_workers = 2 gives best speed (for GPU)\n    train_dataloader = DataLoader(train_dataset, batch_size = None, num_workers = 2) \n    valid_dataloader = DataLoader(valid_dataset, batch_size = None, num_workers = 2) \n    \n    \n    for epoch in range(CFG.NUM_EPOCHS):   \n        \n        torch.cuda.empty_cache()\n        gc.collect()\n        \n        start_time = time.time()\n        \n        #train\n        avg_train_loss = train_fn(train_dataloader, num_train_batches, model, criterion, optimizer, epoch, scheduler, device)\n        \n        torch.save({'model': model.state_dict()}, CFG.OUTPUT_DIR + f\"BERT_For_Patents_FineTuned_{epoch+1}.pth\")\n        \n        #eval\n        overall_val_loss = valid_fn(valid_dataloader, num_val_batches, model, criterion, epoch, device)\n        \n        elapsed = time.time() - start_time\n        \n        print(f\"Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}, overall_val_loss: {overall_val_loss: 4f} time: {elapsed:.0f}s \\n\")\n        \n            \n        if overall_val_loss < best_loss:\n            best_loss = overall_val_loss\n            best_epoch = epoch + 1\n            torch.save({'model': model.state_dict()}, CFG.OUTPUT_DIR  + \"BERT_For_Patents_FineTuned.pth\")\n            \n    print(f'Best Epoch {best_epoch} - Best Loss: {best_loss:.4f}')\n            \n    torch.cuda.empty_cache()\n    gc.collect()\n              ","metadata":{"id":"tVEz812xC0_S","execution":{"iopub.status.busy":"2022-10-28T14:25:17.697821Z","iopub.execute_input":"2022-10-28T14:25:17.698260Z","iopub.status.idle":"2022-10-28T14:25:17.715031Z","shell.execute_reply.started":"2022-10-28T14:25:17.698228Z","shell.execute_reply":"2022-10-28T14:25:17.713690Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def inference_loop():\n    \n    model = PatentClassificationModel(CFG)\n    model.to(device)\n    state = torch.load(CFG.TRAINED_MODEL_PATH, map_location=device)\n    model.load_state_dict(state['model'])\n    \n    num_test_batches = math.ceil(len(test_df)/CFG.BATCH_SIZE)\n    \n    criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n    \n    test_dataset = PatentClassification_TrainDataset(CFG, cpc_code_section_dict, test_df)\n    \n    test_dataloader = DataLoader(test_dataset, batch_size = None, num_workers = 2) \n    \n    start_time = time.time()\n    \n    overall_test_loss = infer_fn(test_dataloader, num_test_batches, model, criterion, device)\n    \n    elapsed = time.time() - start_time\n    \n    print(f\"Testing Loss: {overall_test_loss: .4f} \\n Time Elapsed: {elapsed}\")\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-10-28T14:25:17.913437Z","iopub.execute_input":"2022-10-28T14:25:17.913804Z","iopub.status.idle":"2022-10-28T14:25:17.923457Z","shell.execute_reply.started":"2022-10-28T14:25:17.913773Z","shell.execute_reply":"2022-10-28T14:25:17.922402Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Connect to Weights and Biases","metadata":{}},{"cell_type":"code","source":"import wandb\nsecret_value_0 = \"9dfa4e7926f6f0a53bbd5b5e9976019a1f8eb09a\"\nwandb.login(key=secret_value_0)\nrun = wandb.init(project='PatentClassification', \n                     name='Train',\n                     job_type=\"train\",\n                     anonymous=None)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T14:23:14.806359Z","iopub.execute_input":"2022-10-28T14:23:14.806609Z","iopub.status.idle":"2022-10-28T14:23:24.300743Z","shell.execute_reply.started":"2022-10-28T14:23:14.806586Z","shell.execute_reply":"2022-10-28T14:23:24.299620Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marjundeshmukh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221028_142317-15mwejs7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/arjundeshmukh/PatentClassification/runs/15mwejs7\" target=\"_blank\">Train</a></strong> to <a href=\"https://wandb.ai/arjundeshmukh/PatentClassification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}}]},{"cell_type":"code","source":"if __name__ == '__main__':\n    \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    if CFG.F_TRAIN:\n        train_loop()\n    else:\n        inference_loop()\n        \n        ","metadata":{"id":"oKG0pRqtC0_T","outputId":"32abe0e2-c720-48cf-e97b-3fbca6abf802","execution":{"iopub.status.busy":"2022-10-28T14:25:27.730670Z","iopub.execute_input":"2022-10-28T14:25:27.731054Z","iopub.status.idle":"2022-10-28T14:25:46.115214Z","shell.execute_reply.started":"2022-10-28T14:25:27.731018Z","shell.execute_reply":"2022-10-28T14:25:46.112660Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at ../input/bert-for-patents/bert-for-patents-pytorch were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"=========================== Training Model: Epoch 1 =====================================\nEpoch: [1][1/18101] Elapsed 0m 3s (remain 931m 20s) Loss: 0.6874(0.6874) Grad (Invalid): 0.0000  LR: 0.00099999  \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/802420363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF_TRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minference_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/990314636.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"BERT_For_Patents_FineTuned_{epoch+1}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1212971362.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_dataloader, num_batches, model, criterion, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mloss_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"id":"gx8HH0lJKtpq","execution":{"iopub.status.busy":"2022-10-28T14:25:23.782121Z","iopub.execute_input":"2022-10-28T14:25:23.782487Z","iopub.status.idle":"2022-10-28T14:25:27.728506Z","shell.execute_reply.started":"2022-10-28T14:25:23.782458Z","shell.execute_reply":"2022-10-28T14:25:27.727401Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">Train</strong>: <a href=\"https://wandb.ai/arjundeshmukh/PatentClassification/runs/15mwejs7\" target=\"_blank\">https://wandb.ai/arjundeshmukh/PatentClassification/runs/15mwejs7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20221028_142317-15mwejs7/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}